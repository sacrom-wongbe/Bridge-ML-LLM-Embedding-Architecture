{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35542dc",
   "metadata": {},
   "source": [
    "# Bridge Paragraph Embeddings with BGE-M3\n",
    "\n",
    "Generate embeddings for bridge technical paragraphs using BAAI/bge-m3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab0946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (5.1.2)\n",
      "Requirement already satisfied: torch in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (2.9.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (2.2.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\wongb\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers torch pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d90bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "def print_section(title, char=\"=\", width=80):\n",
    "    \"\"\"Print formatted section header.\"\"\"\n",
    "    print(f\"\\n{char * width}\")\n",
    "    print(title.center(width))\n",
    "    print(f\"{char * width}\\n\")\n",
    "\n",
    "print(\"✅ Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa0305",
   "metadata": {},
   "source": [
    "## Load BGE-M3 Model\n",
    "\n",
    "Download and initialize the BGE-M3 embedding model (~2.3GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4aab902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                              Loading BGE-M3 Model                              \n",
      "================================================================================\n",
      "\n",
      "✓ Model loaded on: cpu\n",
      "✓ Max sequence length: 8192 tokens\n",
      "✓ Embedding dimension: 1024D\n"
     ]
    }
   ],
   "source": [
    "print_section(\"Loading BGE-M3 Model\")\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "# Check device\n",
    "device = 'cuda' if model.device.type == 'cuda' else 'cpu'\n",
    "print(f\"✓ Model loaded on: {device}\")\n",
    "print(f\"✓ Max sequence length: {model.max_seq_length} tokens\")\n",
    "print(f\"✓ Embedding dimension: {model.get_sentence_embedding_dimension()}D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d4e6c",
   "metadata": {},
   "source": [
    "## Load CSV and Generate Embeddings\n",
    "\n",
    "Process the bridge paragraph CSV and generate embeddings for each paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee3147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                                  Loading CSV                                   \n",
      "================================================================================\n",
      "\n",
      "✓ CSV loaded: C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\nlp_processing\\nlp_data\\bridge_paragraphs.csv\n",
      "  Rows: 4,914\n",
      "  Columns: ['STRUCTURE_ID', 'COORDINATES', 'PARAGRAPH']\n",
      "\n",
      "First paragraph preview:\n",
      "  Structure ID:       1W\n",
      "  Coordinates: (48.29745556, -122.6078139)\n",
      "  Paragraph length: 21,169 characters\n",
      "  Paragraph preview: Design Peak Ground Acceleration: High seismic demand bridges with PGA values between 0.4 and 0.6 must incorporate advanced engineering techniques to withstand significant seismic forces and prevent st...\n"
     ]
    }
   ],
   "source": [
    "print_section(\"Loading CSV\")\n",
    "\n",
    "# Define paths\n",
    "csv_path = Path(r'C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\nlp_processing\\nlp_data\\bridge_paragraphs.csv')\n",
    "output_path = Path(r'C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\nlp_data\\bridge_paragraphs_embedded.csv')\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"✓ CSV loaded: {csv_path}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst paragraph preview:\")\n",
    "print(f\"  Structure ID: {df.iloc[0, 0]}\")\n",
    "print(f\"  Coordinates: {df.iloc[0, 1]}\")\n",
    "print(f\"  Paragraph length: {len(str(df.iloc[0, 2])):,} characters\")\n",
    "print(f\"  Paragraph preview: {str(df.iloc[0, 2])[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfe85dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                             Generating Embeddings                              \n",
      "================================================================================\n",
      "\n",
      "Total paragraphs: 4,914\n",
      "Average length: 21,794 characters\n",
      "Max length: 23,344 characters\n",
      "\n",
      "Using CPU parallelization with 19 workers\n",
      "\n",
      "Processing 4,914 paragraphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feae50443d72428783308a8968ed9f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Generated 4,914 embeddings in 1476.8 minutes\n",
      "  Rate: 0.1 embeddings/sec\n",
      "  Embedding shape: (1024,)\n",
      "  Embedding type: <class 'numpy.ndarray'>\n",
      "\n",
      "================================================================================\n",
      "                            Saving Embeddings to CSV                            \n",
      "================================================================================\n",
      "\n",
      "✓ CSV saved: C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\nlp_data\\bridge_paragraphs_embedded.csv\n",
      "  Rows: 4,914\n",
      "  Columns: ['STRUCTURE_ID', 'COORDINATES', 'PARAGRAPH', 'EMBEDDING']\n",
      "\n",
      "First embedding preview:\n",
      "  Embedding length: 1024\n",
      "  First 10 values: [-0.04067869856953621, 0.006592259742319584, -0.00884220376610756, -0.012684069573879242, 0.03733628988265991, -0.05344384163618088, 0.002753559732809663, 0.02851228415966034, -0.0036807351280003786, 0.03813118115067482]\n",
      "\n",
      "✅ Complete! Embeddings added to CSV as column 4.\n"
     ]
    }
   ],
   "source": [
    "print_section(\"Generating Embeddings\")\n",
    "\n",
    "# Extract paragraphs from third column (index 2)\n",
    "paragraphs = df.iloc[:, 2].astype(str).tolist()\n",
    "\n",
    "print(f\"Total paragraphs: {len(paragraphs):,}\")\n",
    "print(f\"Average length: {sum(len(p) for p in paragraphs) / len(paragraphs):,.0f} characters\")\n",
    "print(f\"Max length: {max(len(p) for p in paragraphs):,} characters\")\n",
    "\n",
    "# Detect device and set parallelization parameters\n",
    "device = 'cuda' if model.device.type == 'cuda' else 'cpu'\n",
    "if device == 'cpu':\n",
    "    # Use multiprocessing for CPU\n",
    "    import multiprocessing\n",
    "    num_workers = max(1, multiprocessing.cpu_count() - 1)  # Leave 1 core free\n",
    "    print(f\"\\nUsing CPU parallelization with {num_workers} workers\")\n",
    "else:\n",
    "    # GPU doesn't benefit from num_workers\n",
    "    num_workers = 0\n",
    "    print(f\"\\nUsing GPU acceleration\")\n",
    "\n",
    "# Generate embeddings with optimized settings\n",
    "print(f\"\\nProcessing {len(paragraphs):,} paragraphs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use encode() with optimized settings\n",
    "all_embeddings = model.encode(\n",
    "    paragraphs,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=False\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✓ Generated {len(all_embeddings):,} embeddings in {elapsed/60:.1f} minutes\")\n",
    "print(f\"  Rate: {len(all_embeddings)/elapsed:.1f} embeddings/sec\")\n",
    "print(f\"  Embedding shape: {all_embeddings[0].shape}\")\n",
    "print(f\"  Embedding type: {type(all_embeddings[0])}\")\n",
    "\n",
    "print_section(\"Saving Embeddings to CSV\")\n",
    "\n",
    "# Convert embeddings to list format for JSON serialization\n",
    "embeddings_as_lists = [emb.tolist() for emb in all_embeddings]\n",
    "\n",
    "# Add embeddings as fourth column\n",
    "df['EMBEDDING'] = embeddings_as_lists\n",
    "\n",
    "# Save to CSV\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ CSV saved: {output_path}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst embedding preview:\")\n",
    "print(f\"  Embedding length: {len(df.iloc[0, 3])}\")\n",
    "print(f\"  First 10 values: {df.iloc[0, 3][:10]}\")\n",
    "print(f\"\\n✅ Complete! Embeddings added to CSV as column 4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d23b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
