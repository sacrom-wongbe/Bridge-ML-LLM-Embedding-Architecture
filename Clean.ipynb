{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6a7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set pandas display options to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def print_section(title, char=\"=\", width=80):\n",
    "    \"\"\"Print a formatted section header.\"\"\"\n",
    "    print(f\"\\n{char * width}\")\n",
    "    print(title.center(width))\n",
    "    print(f\"{char * width}\\n\")\n",
    "\n",
    "def print_item(label, value, indent=2):\n",
    "    \"\"\"Print a labeled item with consistent formatting.\"\"\"\n",
    "    spaces = \" \" * indent\n",
    "    print(f\"{spaces}{label}: {value}\")\n",
    "\n",
    "def clean_csv_duplicates(folder_path, structure_coords_path, suffix=\"_cleaned\"):\n",
    "    \"\"\"\n",
    "    Remove duplicate structure ID and coordinate pairs from all CSVs in a folder.\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to folder containing CSV files to clean\n",
    "        structure_coords_path: Path to structure_coordinates.csv (won't be modified)\n",
    "        suffix: Suffix to append to cleaned files (default: \"_cleaned\")\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    structure_coords_file = Path(structure_coords_path)\n",
    "    \n",
    "    # Get all CSV files except structure_coordinates.csv\n",
    "    csv_files = [f for f in folder.glob(\"*.csv\") \n",
    "                 if f.name != structure_coords_file.name and not f.name.endswith(f\"{suffix}.csv\")]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"\\nâš ï¸  No CSV files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print_section(f\"CSV DUPLICATE CLEANER - Processing {len(csv_files)} files\")\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\n{'â”€' * 80}\")\n",
    "        print(f\"ğŸ“„ FILE: {csv_file.name}\")\n",
    "        print(f\"{'â”€' * 80}\")\n",
    "        \n",
    "        # Load CSV\n",
    "        df = pd.read_csv(csv_file)\n",
    "        original_rows = len(df)\n",
    "        \n",
    "        # Get structure ID column (first column)\n",
    "        id_column = df.columns[0]\n",
    "        \n",
    "        # Check if COORDINATES column exists\n",
    "        if 'COORDINATES' not in df.columns:\n",
    "            print(f\"  âš ï¸  No COORDINATES column found - SKIPPING\\n\")\n",
    "            summary_data.append({\n",
    "                'File': csv_file.name,\n",
    "                'Status': 'Skipped - No COORDINATES',\n",
    "                'Original Rows': original_rows,\n",
    "                'Final Rows': original_rows,\n",
    "                'Duplicates Removed': 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Report on null values\n",
    "        null_ids = df[id_column].isna().sum()\n",
    "        null_coords = df['COORDINATES'].isna().sum()\n",
    "        \n",
    "        print_item(\"Structure ID Column\", id_column)\n",
    "        print_item(\"Original Rows\", f\"{original_rows:,}\")\n",
    "        \n",
    "        if null_ids > 0:\n",
    "            print_item(\"Null Structure IDs\", f\"âš ï¸  {null_ids:,} rows\")\n",
    "        if null_coords > 0:\n",
    "            print_item(\"Null COORDINATES\", f\"âš ï¸  {null_coords:,} rows\")\n",
    "        \n",
    "        # Remove duplicate (structure ID, COORDINATES) pairs\n",
    "        # Keep the first occurrence\n",
    "        df_cleaned = df.drop_duplicates(subset=[id_column, 'COORDINATES'], keep='first')\n",
    "        \n",
    "        duplicates_removed = original_rows - len(df_cleaned)\n",
    "        \n",
    "        if duplicates_removed > 0:\n",
    "            print_item(\"Duplicates Found\", f\"ğŸ”´ {duplicates_removed:,} rows\")\n",
    "            print_item(\"Action\", \"Removed duplicates, kept first occurrence\")\n",
    "        else:\n",
    "            print_item(\"Duplicates Found\", \"âœ… None\")\n",
    "        \n",
    "        print_item(\"Final Rows\", f\"{len(df_cleaned):,}\")\n",
    "        \n",
    "        # Save cleaned CSV\n",
    "        output_name = csv_file.stem + suffix + csv_file.suffix\n",
    "        output_path = folder / output_name\n",
    "        df_cleaned.to_csv(output_path, index=False)\n",
    "        print_item(\"Saved As\", output_name)\n",
    "        \n",
    "        summary_data.append({\n",
    "            'File': csv_file.name,\n",
    "            'Status': 'Cleaned' if duplicates_removed > 0 else 'No Changes',\n",
    "            'Original Rows': original_rows,\n",
    "            'Final Rows': len(df_cleaned),\n",
    "            'Duplicates Removed': duplicates_removed\n",
    "        })\n",
    "    \n",
    "    # Display summary table\n",
    "    print_section(\"SUMMARY\", char=\"=\")\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df)\n",
    "    \n",
    "    total_duplicates = summary_df['Duplicates Removed'].sum()\n",
    "    print(f\"\\nâœ… COMPLETE: Removed {total_duplicates:,} total duplicate rows across all files\\n\")\n",
    "\n",
    "def clean_and_verify(folder_path, structure_coords_path, suffix=\"_cleaned\"):\n",
    "    \"\"\"\n",
    "    Clean CSVs and verify against structure_coordinates.csv source of truth.\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to folder containing CSV files to clean\n",
    "        structure_coords_path: Path to structure_coordinates.csv\n",
    "        suffix: Suffix to append to cleaned files\n",
    "    \"\"\"\n",
    "    # Load structure coordinates as source of truth\n",
    "    structure_coords = pd.read_csv(structure_coords_path)\n",
    "    id_col_truth = structure_coords.columns[0]\n",
    "    \n",
    "    print_section(\"SOURCE OF TRUTH\")\n",
    "    print_item(\"File\", Path(structure_coords_path).name)\n",
    "    print_item(\"Total Structure IDs\", f\"{len(structure_coords):,}\")\n",
    "    print_item(\"Valid Coordinates\", f\"{structure_coords['COORDINATES'].notna().sum():,}\")\n",
    "    \n",
    "    # First clean duplicates\n",
    "    clean_csv_duplicates(folder_path, structure_coords_path, suffix)\n",
    "    \n",
    "    # Now verify cleaned files\n",
    "    folder = Path(folder_path)\n",
    "    cleaned_files = list(folder.glob(f\"*{suffix}.csv\"))\n",
    "    \n",
    "    if cleaned_files:\n",
    "        print_section(\"VERIFICATION AGAINST SOURCE OF TRUTH\", char=\"=\")\n",
    "        \n",
    "        verification_data = []\n",
    "        \n",
    "        for csv_file in cleaned_files:\n",
    "            print(f\"\\n{'â”€' * 80}\")\n",
    "            print(f\"ğŸ” VERIFYING: {csv_file.name}\")\n",
    "            print(f\"{'â”€' * 80}\")\n",
    "            \n",
    "            df = pd.read_csv(csv_file)\n",
    "            id_column = df.columns[0]\n",
    "            \n",
    "            if 'COORDINATES' in df.columns:\n",
    "                # Check how many structure IDs exist in source of truth\n",
    "                valid_ids = df[id_column].isin(structure_coords[id_col_truth]).sum()\n",
    "                invalid_ids = len(df) - valid_ids\n",
    "                \n",
    "                print_item(\"Total Rows\", f\"{len(df):,}\")\n",
    "                print_item(\"IDs in Source of Truth\", f\"âœ… {valid_ids:,} / {len(df):,}\")\n",
    "                \n",
    "                if invalid_ids > 0:\n",
    "                    print_item(\"IDs NOT in Source\", f\"âš ï¸  {invalid_ids:,}\")\n",
    "                \n",
    "                # Check coordinate mismatches\n",
    "                merged = df.merge(\n",
    "                    structure_coords[[id_col_truth, 'COORDINATES']], \n",
    "                    left_on=id_column, \n",
    "                    right_on=id_col_truth, \n",
    "                    how='inner',\n",
    "                    suffixes=('_file', '_truth')\n",
    "                )\n",
    "                \n",
    "                coord_status = \"N/A\"\n",
    "                mismatches = 0\n",
    "                \n",
    "                if len(merged) > 0:\n",
    "                    mismatches = (merged['COORDINATES_file'] != merged['COORDINATES_truth']).sum()\n",
    "                    if mismatches > 0:\n",
    "                        coord_status = f\"âš ï¸  {mismatches:,} mismatches\"\n",
    "                        print_item(\"Coordinate Mismatches\", f\"ğŸ”´ {mismatches:,} found\")\n",
    "                    else:\n",
    "                        coord_status = \"âœ… All match\"\n",
    "                        print_item(\"Coordinate Verification\", \"âœ… All coordinates match source\")\n",
    "                \n",
    "                verification_data.append({\n",
    "                    'File': csv_file.name,\n",
    "                    'Total Rows': len(df),\n",
    "                    'Valid IDs': valid_ids,\n",
    "                    'Invalid IDs': invalid_ids,\n",
    "                    'Coord Status': coord_status\n",
    "                })\n",
    "        \n",
    "        # Display verification summary\n",
    "        print_section(\"VERIFICATION SUMMARY\", char=\"=\")\n",
    "        verification_df = pd.DataFrame(verification_data)\n",
    "        display(verification_df)\n",
    "        \n",
    "        print(\"\\nâœ… VERIFICATION COMPLETE\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7fade",
   "metadata": {},
   "source": [
    "## Example Usage - Basic Cleaning\n",
    "\n",
    "Remove duplicate (structure ID, COORDINATES) pairs from all CSVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd7b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                   CSV DUPLICATE CLEANER - Processing 8 files                   \n",
      "================================================================================\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: design_maps.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 4,914\n",
      "  Duplicates Found: âœ… None\n",
      "  Final Rows: 4,914\n",
      "  Saved As: design_maps_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: macrostrat.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 4,914\n",
      "  Duplicates Found: âœ… None\n",
      "  Final Rows: 4,914\n",
      "  Saved As: macrostrat_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_nominal.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nbi_nominal_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_numerical.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nbi_numerical_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_numerical_coded.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nbi_numerical_coded_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_semantic_nominal_derived.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  âš ï¸  No COORDINATES column found - SKIPPING\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nfhl_fema_flood.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nfhl_fema_flood_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nshm_hazard_grid.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  âš ï¸  No COORDINATES column found - SKIPPING\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                                    SUMMARY                                     \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Original Rows</th>\n",
       "      <th>Final Rows</th>\n",
       "      <th>Duplicates Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>design_maps.csv</td>\n",
       "      <td>No Changes</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macrostrat.csv</td>\n",
       "      <td>No Changes</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nbi_nominal.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nbi_numerical.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nbi_numerical_coded.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nbi_semantic_nominal_derived.csv</td>\n",
       "      <td>Skipped - No COORDINATES</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nfhl_fema_flood.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nshm_hazard_grid.csv</td>\n",
       "      <td>Skipped - No COORDINATES</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File                    Status  Original Rows  \\\n",
       "0                   design_maps.csv                No Changes           4914   \n",
       "1                    macrostrat.csv                No Changes           4914   \n",
       "2                   nbi_nominal.csv                   Cleaned          17328   \n",
       "3                 nbi_numerical.csv                   Cleaned          17328   \n",
       "4           nbi_numerical_coded.csv                   Cleaned          17328   \n",
       "5  nbi_semantic_nominal_derived.csv  Skipped - No COORDINATES           4914   \n",
       "6               nfhl_fema_flood.csv                   Cleaned          17328   \n",
       "7              nshm_hazard_grid.csv  Skipped - No COORDINATES           4914   \n",
       "\n",
       "   Final Rows  Duplicates Removed  \n",
       "0        4914                   0  \n",
       "1        4914                   0  \n",
       "2        4914               12414  \n",
       "3        4914               12414  \n",
       "4        4914               12414  \n",
       "5        4914                   0  \n",
       "6        4914               12414  \n",
       "7        4914                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… COMPLETE: Removed 49,656 total duplicate rows across all files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic cleaning - just remove duplicates\n",
    "folder = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\"\n",
    "structure_coords = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\\structure_coordinates.csv\"\n",
    "\n",
    "clean_csv_duplicates(folder, structure_coords, suffix=\"_cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c0754",
   "metadata": {},
   "source": [
    "## Example Usage - Clean and Verify\n",
    "\n",
    "Remove duplicates AND verify against structure_coordinates.csv as source of truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e899b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                                SOURCE OF TRUTH                                 \n",
      "================================================================================\n",
      "\n",
      "  File: structure_coordinates.csv\n",
      "  Total Structure IDs: 4,914\n",
      "  Valid Coordinates: 4,914\n",
      "\n",
      "================================================================================\n",
      "                   CSV DUPLICATE CLEANER - Processing 8 files                   \n",
      "================================================================================\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: design_maps.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 4,914\n",
      "  Duplicates Found: âœ… None\n",
      "  Final Rows: 4,914\n",
      "  Saved As: design_maps_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: macrostrat.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 4,914\n",
      "  Duplicates Found: âœ… None\n",
      "  Final Rows: 4,914\n",
      "  Saved As: macrostrat_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_nominal.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nbi_nominal_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_numerical.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nbi_numerical_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_numerical_coded.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nbi_numerical_coded_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nbi_semantic_nominal_derived.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  âš ï¸  No COORDINATES column found - SKIPPING\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nfhl_fema_flood.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Structure ID Column: STRUCTURE_ID\n",
      "  Original Rows: 17,328\n",
      "  Duplicates Found: ğŸ”´ 12,414 rows\n",
      "  Action: Removed duplicates, kept first occurrence\n",
      "  Final Rows: 4,914\n",
      "  Saved As: nfhl_fema_flood_cleaned.csv\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“„ FILE: nshm_hazard_grid.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  âš ï¸  No COORDINATES column found - SKIPPING\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                                    SUMMARY                                     \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Status</th>\n",
       "      <th>Original Rows</th>\n",
       "      <th>Final Rows</th>\n",
       "      <th>Duplicates Removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>design_maps.csv</td>\n",
       "      <td>No Changes</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macrostrat.csv</td>\n",
       "      <td>No Changes</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nbi_nominal.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nbi_numerical.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nbi_numerical_coded.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nbi_semantic_nominal_derived.csv</td>\n",
       "      <td>Skipped - No COORDINATES</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nfhl_fema_flood.csv</td>\n",
       "      <td>Cleaned</td>\n",
       "      <td>17328</td>\n",
       "      <td>4914</td>\n",
       "      <td>12414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nshm_hazard_grid.csv</td>\n",
       "      <td>Skipped - No COORDINATES</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File                    Status  Original Rows  \\\n",
       "0                   design_maps.csv                No Changes           4914   \n",
       "1                    macrostrat.csv                No Changes           4914   \n",
       "2                   nbi_nominal.csv                   Cleaned          17328   \n",
       "3                 nbi_numerical.csv                   Cleaned          17328   \n",
       "4           nbi_numerical_coded.csv                   Cleaned          17328   \n",
       "5  nbi_semantic_nominal_derived.csv  Skipped - No COORDINATES           4914   \n",
       "6               nfhl_fema_flood.csv                   Cleaned          17328   \n",
       "7              nshm_hazard_grid.csv  Skipped - No COORDINATES           4914   \n",
       "\n",
       "   Final Rows  Duplicates Removed  \n",
       "0        4914                   0  \n",
       "1        4914                   0  \n",
       "2        4914               12414  \n",
       "3        4914               12414  \n",
       "4        4914               12414  \n",
       "5        4914                   0  \n",
       "6        4914               12414  \n",
       "7        4914                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… COMPLETE: Removed 49,656 total duplicate rows across all files\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                      VERIFICATION AGAINST SOURCE OF TRUTH                      \n",
      "================================================================================\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” VERIFYING: design_maps_cleaned.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Total Rows: 4,914\n",
      "  IDs in Source of Truth: âœ… 4,914 / 4,914\n",
      "  Coordinate Mismatches: ğŸ”´ 12,414 found\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” VERIFYING: macrostrat_cleaned.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Total Rows: 4,914\n",
      "  IDs in Source of Truth: âœ… 4,914 / 4,914\n",
      "  Coordinate Mismatches: ğŸ”´ 12,414 found\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” VERIFYING: nbi_nominal_cleaned.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Total Rows: 4,914\n",
      "  IDs in Source of Truth: âœ… 4,914 / 4,914\n",
      "  Coordinate Mismatches: ğŸ”´ 12,414 found\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” VERIFYING: nbi_numerical_cleaned.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Total Rows: 4,914\n",
      "  IDs in Source of Truth: âœ… 4,914 / 4,914\n",
      "  Coordinate Mismatches: ğŸ”´ 12,414 found\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” VERIFYING: nbi_numerical_coded_cleaned.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Total Rows: 4,914\n",
      "  IDs in Source of Truth: âœ… 4,914 / 4,914\n",
      "  Coordinate Mismatches: ğŸ”´ 12,414 found\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” VERIFYING: nfhl_fema_flood_cleaned.csv\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Total Rows: 4,914\n",
      "  IDs in Source of Truth: âœ… 4,914 / 4,914\n",
      "  Coordinate Mismatches: ğŸ”´ 12,414 found\n",
      "\n",
      "================================================================================\n",
      "                              VERIFICATION SUMMARY                              \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Total Rows</th>\n",
       "      <th>Valid IDs</th>\n",
       "      <th>Invalid IDs</th>\n",
       "      <th>Coord Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>design_maps_cleaned.csv</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>âš ï¸  12,414 mismatches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macrostrat_cleaned.csv</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>âš ï¸  12,414 mismatches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nbi_nominal_cleaned.csv</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>âš ï¸  12,414 mismatches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nbi_numerical_cleaned.csv</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>âš ï¸  12,414 mismatches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nbi_numerical_coded_cleaned.csv</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>âš ï¸  12,414 mismatches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nfhl_fema_flood_cleaned.csv</td>\n",
       "      <td>4914</td>\n",
       "      <td>4914</td>\n",
       "      <td>0</td>\n",
       "      <td>âš ï¸  12,414 mismatches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              File  Total Rows  Valid IDs  Invalid IDs  \\\n",
       "0          design_maps_cleaned.csv        4914       4914            0   \n",
       "1           macrostrat_cleaned.csv        4914       4914            0   \n",
       "2          nbi_nominal_cleaned.csv        4914       4914            0   \n",
       "3        nbi_numerical_cleaned.csv        4914       4914            0   \n",
       "4  nbi_numerical_coded_cleaned.csv        4914       4914            0   \n",
       "5      nfhl_fema_flood_cleaned.csv        4914       4914            0   \n",
       "\n",
       "            Coord Status  \n",
       "0  âš ï¸  12,414 mismatches  \n",
       "1  âš ï¸  12,414 mismatches  \n",
       "2  âš ï¸  12,414 mismatches  \n",
       "3  âš ï¸  12,414 mismatches  \n",
       "4  âš ï¸  12,414 mismatches  \n",
       "5  âš ï¸  12,414 mismatches  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… VERIFICATION COMPLETE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean and verify against source of truth\n",
    "folder = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\"\n",
    "structure_coords = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\\structure_coordinates.csv\"\n",
    "\n",
    "clean_and_verify(folder, structure_coords, suffix=\"_cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b0e68",
   "metadata": {},
   "source": [
    "## Simple Coordinate Append\n",
    "\n",
    "Append COORDINATES column from structure_coordinates.csv to target CSVs, placing it at position 1 (second column). Assumes row order matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7749310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def append_coordinates_simple(csv_path, structure_coords_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Append COORDINATES column from structure_coordinates.csv to target CSV at position 1.\n",
    "    Assumes row order matches between files.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to target CSV file\n",
    "        structure_coords_path: Path to structure_coordinates.csv\n",
    "        output_path: Optional output path (defaults to overwriting input)\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = csv_path\n",
    "    \n",
    "    # Load files\n",
    "    df = pd.read_csv(csv_path)\n",
    "    coords = pd.read_csv(structure_coords_path)\n",
    "    \n",
    "    # Check row count match\n",
    "    if len(df) != len(coords):\n",
    "        print(f\"âš ï¸  WARNING: Row count mismatch!\")\n",
    "        print(f\"   Target CSV: {len(df):,} rows\")\n",
    "        print(f\"   Coordinates CSV: {len(coords):,} rows\")\n",
    "        return None\n",
    "    \n",
    "    # Remove COORDINATES if it already exists\n",
    "    if 'COORDINATES' in df.columns:\n",
    "        df = df.drop(columns=['COORDINATES'])\n",
    "        print(f\"â„¹ï¸  Removed existing COORDINATES column\")\n",
    "    \n",
    "    # Insert COORDINATES at position 1 (second column)\n",
    "    df.insert(1, 'COORDINATES', coords['COORDINATES'])\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Saved: {Path(output_path).name}\")\n",
    "    print(f\"   Columns: {list(df.columns[:3])}... ({len(df.columns)} total)\")\n",
    "    print(f\"   Rows: {len(df):,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def append_coordinates_folder(folder_path, structure_coords_path, suffix=\"_coords\"):\n",
    "    \"\"\"\n",
    "    Append COORDINATES to all CSVs in a folder (except structure_coordinates.csv).\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to folder containing CSV files\n",
    "        structure_coords_path: Path to structure_coordinates.csv\n",
    "        suffix: Suffix for output files (default: \"_coords\")\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    structure_coords_file = Path(structure_coords_path)\n",
    "    \n",
    "    # Get all CSV files except structure_coordinates.csv and already processed files\n",
    "    csv_files = [f for f in folder.glob(\"*.csv\") \n",
    "                 if f.name != structure_coords_file.name \n",
    "                 and not f.name.endswith(f\"{suffix}.csv\")]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"âš ï¸  No CSV files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"APPENDING COORDINATES TO {len(csv_files)} FILES\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for idx, csv_file in enumerate(csv_files, 1):\n",
    "        print(f\"[{idx}/{len(csv_files)}] ğŸ“„ {csv_file.name}\")\n",
    "        \n",
    "        # Create output path with suffix\n",
    "        output_name = csv_file.stem + suffix + csv_file.suffix\n",
    "        output_path = folder / output_name\n",
    "        \n",
    "        try:\n",
    "            append_coordinates_simple(csv_file, structure_coords_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"âœ… COMPLETE\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c06dec",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63b9288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: nshm_hazard_grid.csv\n",
      "   Columns: ['STRUCTURE_ID', 'COORDINATES', 'PGA_475']... (14 total)\n",
      "   Rows: 4,914\n",
      "\n",
      "First 3 rows, first 4 columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STRUCTURE_ID</th>\n",
       "      <th>COORDINATES</th>\n",
       "      <th>PGA_475</th>\n",
       "      <th>PGA_975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>(47.98571667, -122.2271222)</td>\n",
       "      <td>0.259826</td>\n",
       "      <td>0.364282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>(47.697975, -122.6195)</td>\n",
       "      <td>0.386814</td>\n",
       "      <td>0.549207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>(48.21215, -121.9331306)</td>\n",
       "      <td>0.203070</td>\n",
       "      <td>0.284565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STRUCTURE_ID                  COORDINATES   PGA_475   PGA_975\n",
       "0               (47.98571667, -122.2271222)  0.259826  0.364282\n",
       "1                    (47.697975, -122.6195)  0.386814  0.549207\n",
       "2                  (48.21215, -121.9331306)  0.203070  0.284565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Single file example\n",
    "csv_file = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\\nshm_hazard_grid.csv\"\n",
    "coords_file = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\\structure_coordinates.csv\"\n",
    "\n",
    "df = append_coordinates_simple(csv_file, coords_file)\n",
    "\n",
    "# Show result\n",
    "if df is not None:\n",
    "    print(f\"\\nFirst 3 rows, first 4 columns:\")\n",
    "    display(df.iloc[:3, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process entire folder\n",
    "folder = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\"\n",
    "coords_file = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\enriched_data\\structure_coordinates.csv\"\n",
    "\n",
    "append_coordinates_folder(folder, coords_file, suffix=\"_coords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef98e6",
   "metadata": {},
   "source": [
    "## Check for Duplicate Titles in Schemas\n",
    "\n",
    "Quick script to verify no duplicate titles exist across all schema fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525c14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 7 schema files...\n",
      "\n",
      "ğŸ“Š Total titles found: 121\n",
      "ğŸ“Š Unique titles: 118\n",
      "\n",
      "âš ï¸  Found 3 duplicate titles:\n",
      "\n",
      "  'Approach Guardrail Adequacy' appears 2 times:\n",
      "    - nbi_nominal_schema_master.json: APPR_RAIL_036C\n",
      "    - nbi_nominal_schema_master.json: APPR_RAIL_END_036D\n",
      "\n",
      "  'Route Classification' appears 2 times:\n",
      "    - nbi_nominal_schema_master.json: ROUTE_PREFIX_005B\n",
      "    - nbi_nominal_schema_master.json: SERVICE_LEVEL_005C\n",
      "\n",
      "  'Vertical Clearance' appears 2 times:\n",
      "    - nbi_numerical_coded_schema_master.json: VERT_CLR_OVER_MT_053\n",
      "    - nbi_numerical_coded_schema_master.json: VERT_CLR_UND_054B\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def check_duplicate_titles(schema_folder):\n",
    "    \"\"\"Check for duplicate titles across all schema files.\"\"\"\n",
    "    schema_folder = Path(schema_folder)\n",
    "    \n",
    "    all_titles = []\n",
    "    title_sources = {}  # Track which file each title comes from\n",
    "    \n",
    "    # Get all JSON files\n",
    "    schema_files = sorted(schema_folder.glob(\"*.json\"))\n",
    "    \n",
    "    print(f\"Checking {len(schema_files)} schema files...\\n\")\n",
    "    \n",
    "    for schema_file in schema_files:\n",
    "        with open(schema_file, 'r', encoding='utf-8') as f:\n",
    "            schema = json.load(f)\n",
    "        \n",
    "        for field_name, field_data in schema.items():\n",
    "            if isinstance(field_data, dict) and 'title' in field_data:\n",
    "                title = field_data['title']\n",
    "                all_titles.append(title)\n",
    "                \n",
    "                # Track source\n",
    "                if title not in title_sources:\n",
    "                    title_sources[title] = []\n",
    "                title_sources[title].append((schema_file.name, field_name))\n",
    "    \n",
    "    # Find duplicates\n",
    "    title_counts = Counter(all_titles)\n",
    "    duplicates = {title: count for title, count in title_counts.items() if count > 1}\n",
    "    \n",
    "    print(f\"ğŸ“Š Total titles found: {len(all_titles)}\")\n",
    "    print(f\"ğŸ“Š Unique titles: {len(title_counts)}\")\n",
    "    \n",
    "    if duplicates:\n",
    "        print(f\"\\nâš ï¸  Found {len(duplicates)} duplicate titles:\\n\")\n",
    "        for title, count in sorted(duplicates.items()):\n",
    "            print(f\"  '{title}' appears {count} times:\")\n",
    "            for source_file, field_name in title_sources[title]:\n",
    "                print(f\"    - {source_file}: {field_name}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"\\nâœ… No duplicate titles found!\")\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "# Run check\n",
    "schema_folder = r\"C:\\Users\\wongb\\Bridge-ML\\Bridge-ML-LLM-Embedding-Architecture\\final_schemas\"\n",
    "duplicates = check_duplicate_titles(schema_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffb44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
